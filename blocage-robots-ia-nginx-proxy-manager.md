---
title: Bloquer les robots d‚ÄôIA directement via NGINX Proxy Manager
description: Apprenez √† centraliser le blocage des principaux crawlers d‚ÄôIA dans NGINX Proxy Manager (NPM) en utilisant un fichier de configuration custom. Une alternative efficace aux modifications des fichiers robots.txt individuels.
published: true
date: 2026-02-07T19:19:11.150Z
tags: nginx, proxy, npm, blocage-crawlers, robots, ia, ai, crawlers
editor: markdown
dateCreated: 2025-12-15T23:32:58.582Z
---

## Introduction
Plut√¥t que de modifier les fichiers `robots.txt` de chaque site individuellement (ce qui demande de maintenir des configurations s√©par√©es) :

* Exemple Gitea : [https://wiki.blablalinux.be/fr/robots-txt-gitea-blocage-ia](https://wiki.blablalinux.be/fr/robots-txt-gitea-blocage-ia)
* Exemple WordPress : [https://wiki.blablalinux.be/fr/robots-txt-wordpress-anti-ia](https://wiki.blablalinux.be/fr/robots-txt-wordpress-anti-ia)

... nous allons agir de mani√®re beaucoup plus **efficace et centralis√©e** !

Nous allons impl√©menter le blocage directement au niveau du **proxy inverse**, ici via **NGINX Proxy Manager (NPM)**. Cette m√©thode permet de rejeter la connexion pour les User-Agents cibl√©s *avant* qu'ils n'atteignent l'application cible, √©conomisant ainsi des ressources et simplifiant l'administration.

## 1. Comprendre l‚Äôarchitecture des configurations personnalis√©es de NPM
NGINX Proxy Manager offre des **points d'insertion** (`include`) bien d√©finis dans la configuration NGINX g√©n√©r√©e. Ces points vous permettent d'ajouter des directives personnalis√©es sans modifier les fichiers de configuration de base.

Voici la liste des points d'insertion disponibles dans le r√©pertoire `/data/nginx/custom/` (selon la documentation NPM) :

| Fichier de Configuration Personnalis√© | Emplacement d'Inclusion | Port√©e |
| --- | --- | --- |
| `/data/nginx/custom/root_top.conf` | En haut de `nginx.conf` | Globale |
| `/data/nginx/custom/http_top.conf` | En haut du bloc `http` principal | Globale (HTTP/HTTPS) |
| **`/data/nginx/custom/server_proxy.conf`** | **Fin de chaque bloc `server` de proxy** | **Par h√¥te (recommand√©)** |
| `/data/nginx/custom/http.conf` | Fin du bloc `http` principal | Globale (HTTP/HTTPS) |
| `/data/nginx/custom/root.conf` | √Ä la toute fin de `nginx.conf` | Globale |
| *Autres...* | *Voir la documentation pour `events`, `stream`, etc.* | *Sp√©cifique* |

> **‚ö†Ô∏è Attention : cr√©ation des fichiers**
> **Ces fichiers de configuration personnalis√©s n'existent pas par d√©faut !** Ils sont facultatifs. Vous devez imp√©rativement cr√©er le fichier souhait√© (dans notre cas, `server_proxy.conf`) dans le r√©pertoire `/data/nginx/custom/` avant d'y placer votre code.

Pour plus de d√©tails sur les points d'insertion, consultez la documentation officielle :
‚û°Ô∏è **[NGINX Proxy Manager - Documentation Configuration Avanc√©e](https://nginxproxymanager.com/advanced-config/)**

## 2. Impl√©mentation du blocage anti-IA
Nous allons utiliser le fichier `/data/nginx/custom/server_proxy.conf` pour cibler uniquement les configurations de proxy (les plus courantes pour les services expos√©s).

### √âtape A : cr√©er et √©diter le fichier
Via votre console Linux sur votre h√¥te (Proxmox/Docker) :

```bash
# Assurez-vous d'√™tre dans le bon volume de donn√©es de NPM
# Exemple de cr√©ation (si le volume est mont√© quelque part)
mkdir -p /chemin/vers/data/nginx/custom/
touch /chemin/vers/data/nginx/custom/server_proxy.conf
nano /chemin/vers/data/nginx/custom/server_proxy.conf

```

### √âtape B : ins√©rer le code de blocage
Ajoutez le bloc de code suivant √† l'int√©rieur de `server_proxy.conf` :

```nginx
# --- BLOCAGE CENTRALIS√â DES ROBOTS D'IA ---

# 1. Initialisation de la variable de blocage
set $block 0;

# 2. V√©rification des User-Agents des IA/Crawlers
# Cette expression r√©guli√®re v√©rifie l'en-t√™te http_user_agent
if ($http_user_agent ~* "(AddSearchBot|AI2Bot|AI2Bot\-DeepResearchEval|Ai2Bot\-Dolma|aiHitBot|amazon\-kendra|Amazonbot|AmazonBuyForMe|Andibot|Anomura|anthropic\-ai|Applebot|Applebot\-Extended|atlassian\-bot|Awario|bedrockbot|bigsur\.ai|Bravebot|Brightbot\ 1\.0|BuddyBot|Bytespider|CCBot|Channel3Bot|ChatGLM\-Spider|ChatGPT\ Agent|ChatGPT\-User|Claude\-SearchBot|Claude\-User|Claude\-Web|ClaudeBot|Cloudflare\-AutoRAG|CloudVertexBot|cohere\-ai|cohere\-training\-data\-crawler|Cotoyogi|Crawl4AI|Crawlspace|Datenbank\ Crawler|DeepSeekBot|Devin|Diffbot|DuckAssistBot|Echobot\ Bot|EchoboxBot|FacebookBot|facebookexternalhit|Factset_spyderbot|FirecrawlAgent|FriendlyCrawler|Gemini\-Deep\-Research|Google\-CloudVertexBot|Google\-Extended|Google\-Firebase|Google\-NotebookLM|GoogleAgent\-Mariner|GoogleOther|GoogleOther\-Image|GoogleOther\-Video|GPTBot|iAskBot|iaskspider|iaskspider/2\.0|IbouBot|ICC\-Crawler|ImagesiftBot|imageSpider|img2dataset|ISSCyberRiskCrawler|Kangaroo\ Bot|KlaviyoAIBot|KunatoCrawler|laion\-huggingface\-processor|LAIONDownloader|LCC|LinerBot|Linguee\ Bot|LinkupBot|Manus\-User|meta\-externalagent|Meta\-ExternalAgent|meta\-externalfetcher|Meta\-ExternalFetcher|meta\-webindexer|MistralAI\-User|MistralAI\-User/1\.0|MyCentralAIScraperBot|netEstate\ Imprint\ Crawler|NotebookLM|NovaAct|OAI\-SearchBot|omgili|omgilibot|OpenAI|Operator|PanguBot|Panscient|panscient\.com|Perplexity\-User|PerplexityBot|PetalBot|PhindBot|Poggio\-Citations|Poseidon\ Research\ Crawler|QualifiedBot|QuillBot|quillbot\.com|SBIntuitionsBot|Scrapy|SemrushBot\-OCOB|SemrushBot\-SWA|ShapBot|Sidetrade\ indexer\ bot|Spider|TerraCotta|Thinkbot|TikTokSpider|Timpibot|TwinAgent|VelenPublicWebCrawler|WARDBot|Webzio\-Extended|webzio\-extended|wpbot|WRTNBot|YaK|YandexAdditional|YandexAdditionalBot|YouBot|ZanistaBot)") {
    set $block 1;
}

# 3. EXCEPTION : Autoriser l'acc√®s √† robots.txt
if ($request_uri = "/robots.txt") {
    set $block 0;
}

# 4. Ex√©cution du blocage (retour 403 Forbidden)
if ($block) {
    return 403;
}
# --- FIN BLOCAGE ANTI-IA ---

```

> **üìå Note sur la maintenance**
> Les User-Agents des robots d'IA sont en constante √©volution et de nouveaux crawlers apparaissent r√©guli√®rement. Il est crucial de maintenir la liste ci-dessus √† jour. La liste compl√®te des bots couramment bloqu√©s est inspir√©e de configurations communautaires telles que :
> ‚û°Ô∏è **[AI Robots NGINX Block List sur GitHub](https://github.com/ai-robots-txt/ai.robots.txt/blob/main/nginx-block-ai-bots.conf)**

## 3. Application de la configuration
Apr√®s avoir enregistr√© votre fichier `server_proxy.conf`, vous devez **red√©marrer le conteneur NGINX Proxy Manager** pour qu'il inclue ce nouveau fichier dans la configuration principale et recharge le service NGINX :

```bash
docker restart <nom_du_conteneur_npm>

```

*(Remplacez `<nom_du_conteneur_npm>` par le nom de votre conteneur NPM, par exemple `nginx-proxy-manager`).*

## 4. Test de v√©rification du blocage (depuis votre terminal Linux)
Utilisez l'outil **`curl`** avec l'option `-A` (pour sp√©cifier le User-Agent) afin de simuler l'acc√®s d'un robot bloqu√©, puis d'un utilisateur normal.

### A. Tester avec un robot d'IA (attendu : code 403)
Ex√©cutez la commande suivante en rempla√ßant `votre-site.com` par l'une de vos URL g√©r√©es par NPM :

```bash
# Simuler GPTBot tentant d'acc√©der √† votre page d'accueil
curl -A "GPTBot" -I https://votre-site.com/

```

**R√©sultat attendu :** Vous devriez voir un code de r√©ponse HTTP `403 Forbidden`.

### B. Tester l'exclusion `robots.txt` (attendu : code 200/301/302)
Ciblez `/robots.txt` avec le m√™me User-Agent bloqu√© :

```bash
# Simuler GPTBot tentant d'acc√©der √† robots.txt
curl -A "GPTBot" -I https://votre-site.com/robots.txt

```

**R√©sultat attendu :** Vous devriez obtenir une r√©ponse de succ√®s (`200 OK`) ou une redirection, mais **pas de** `403`.

### C. Tester avec un utilisateur standard (attendu : code 200 ou 301/302)
V√©rifiez l'acc√®s normal sans sp√©cifier de User-Agent bloqu√© :

```bash
# Simuler un navigateur standard
curl -I https://votre-site.com/

```

**R√©sultat attendu :** Vous devriez recevoir une r√©ponse de succ√®s ou la redirection normale de votre application.

Si ces trois tests renvoient les codes attendus, votre configuration est fonctionnelle !

C'est not√©, Amaury ! L'approche d'une **recharge gracieuse (`nginx -s reload`)** est en effet la norme professionnelle pour les changements de configuration NGINX, car elle assure une continuit√© de service maximale.

J'ai r√©int√©gr√© la m√©thode de recharge gracieuse dans le script Bash pour votre section wiki.

Voici la nouvelle section (et la version finale du script) que vous pouvez ajouter √† votre page :

---

## 5. Automatisation de la mise √† jour de la liste de blocage
Pour garantir que votre liste de User-Agents bloqu√©s reste √† jour face √† l'apparition de nouveaux robots d'IA, il est recommand√© d'automatiser la mise √† jour du fichier `server_proxy.conf` depuis la source GitHub communautaire.

### A. Cr√©ation du script de mise √† jour
Cr√©ez le script dans un r√©pertoire d'ex√©cution standard (par exemple, `/usr/local/bin/`) :

```bash
sudo nano /usr/local/bin/update_ai_blocklist.sh

```

Ins√©rez le contenu suivant dans le fichier. **Attention : vous devez adapter les chemins (`CONFIG_FILE`) et le nom du conteneur (`NPM_CONTAINER_NAME`) √† votre installation !**

```bash
#!/bin/bash

# Chemins et noms (√Ä ADAPTER !)
# Chemin de votre fichier de configuration NPM (doit pointer vers le volume mont√©)
CONFIG_FILE="/chemin/vers/data/nginx/custom/server_proxy.conf"
# URL du fichier brut NGINX sur GitHub
GITHUB_URL="https://raw.githubusercontent.com/ai-robots-txt/ai.robots.txt/main/nginx-block-ai-bots.conf"
# Nom de votre conteneur Docker NGINX Proxy Manager
NPM_CONTAINER_NAME="npm" 

# --- D√©but de l'ex√©cution ---

echo "$(date) - D√©marrage de la mise √† jour de la liste de blocage AI..."

# 1. T√©l√©chargement de la nouvelle configuration
if curl -sL "$GITHUB_URL" -o "$CONFIG_FILE.new"; then
    echo "T√©l√©chargement r√©ussi."
else
    echo "Erreur lors du t√©l√©chargement depuis GitHub."
    exit 1
fi

# 2. V√©rification et remplacement du fichier
if [ -s "$CONFIG_FILE.new" ]; then
    # D√©placement du nouveau fichier √† son emplacement final
    mv "$CONFIG_FILE.new" "$CONFIG_FILE"
    echo "Fichier de configuration mis √† jour."

    # 3. Validation de la syntaxe NGINX et recharge gracieuse
    # V√©rification de la syntaxe avant de recharger pour √©viter de casser le proxy.
    if docker exec "$NPM_CONTAINER_NAME" nginx -t &> /dev/null; then
        echo "Syntaxe NGINX OK. Recharge gracieuse en cours..."
        
        # Commande pour une recharge gracieuse (moins disruptive que le restart)
        docker exec "$NPM_CONTAINER_NAME" nginx -s reload
        echo "NGINX recharg√© avec succ√®s."
    else
        echo "ERREUR : Erreur de syntaxe NGINX trouv√©e dans le nouveau fichier."
        echo "Le proxy n'a PAS √©t√© recharg√©. Veuillez v√©rifier le fichier : $CONFIG_FILE"
        # Optionnel : Si vous aviez une ancienne version du fichier, vous pourriez la restaurer ici.
        exit 1
    fi
else
    echo "Le fichier t√©l√©charg√© est vide ou invalide. Aucune action effectu√©e."
    rm -f "$CONFIG_FILE.new" # Nettoyer le fichier invalide
    exit 1
fi

echo "$(date) - Mise √† jour termin√©e."

```

### B. Rendre le script ex√©cutable
Assurez-vous que le script a les permissions d'ex√©cution :

```bash
sudo chmod +x /usr/local/bin/update_ai_blocklist.sh

```

### C. Planification de la t√¢che Cron
Nous allons planifier ce script pour qu'il s'ex√©cute **une fois par semaine** (par exemple, chaque dimanche √† 3h00 du matin).

Ouvrez le crontab :

```bash
sudo crontab -e

```

Ajoutez la ligne suivante √† la fin du fichier Crontab :

```crontab
# Mise √† jour hebdomadaire de la liste de blocage AI pour NGINX Proxy Manager
0 3 * * 0 /usr/local/bin/update_ai_blocklist.sh >> /var/log/update_ai_blocklist.log 2>&1

```

## 6. Test manuel du script de mise √† jour
Avant de faire confiance √† `cron` pour ex√©cuter la t√¢che hebdomadaire, il est essentiel de tester manuellement le script `update_ai_blocklist.sh` pour s'assurer qu'il t√©l√©charge le fichier, met √† jour le chemin correct et recharge NGINX sans interruption.

### A. Ex√©cution du script
Ex√©cutez le script en utilisant la m√™me redirection que celle pr√©vue pour la t√¢che `cron`. Cela enregistrera la sortie dans le fichier journal pour v√©rification :

```bash
# Ex√©cution du script en tant que root (ou l'utilisateur qui g√®re Docker)
sudo /usr/local/bin/update_ai_blocklist.sh >> /var/log/update_ai_blocklist.log 2>&1

```

### B. V√©rification du journal
Consultez le fichier journal pour vous assurer que le script a r√©ussi toutes les √©tapes, notamment le t√©l√©chargement, la v√©rification de la syntaxe NGINX et la recharge gracieuse :

```bash
sudo tail -n 20 /var/log/update_ai_blocklist.log

```

**R√©sultat attendu en cas de succ√®s :**

```
[Date et heure] - D√©marrage de la mise √† jour de la liste de blocage AI...
T√©l√©chargement r√©ussi.
Fichier de configuration mis √† jour.
Syntaxe NGINX OK. Recharge gracieuse en cours...
NGINX recharg√© avec succ√®s.
[Date et heure] - Mise √† jour termin√©e.

```

### C. Validation finale (test du proxy)
M√™me si le journal indique une r√©ussite, utilisez la commande `curl` document√©e dans la section 4 pour confirmer que le service est op√©rationnel et que la liste de blocage mise √† jour est active :

```bash
# Test du blocage (doit retourner 403 Forbidden)
curl -A "GPTBot" -I https://votre-site.com/

```

Si le test renvoie `HTTP/2 403`, le script a fonctionn√© parfaitement et la t√¢che `cron` peut √™tre planifi√©e en toute confiance.

## 7. Retours d'exp√©rience : Le cas des r√©seaux sociaux (Facebook OGP)

### Le Probl√®me : Disparition des pr√©visualisations

Lors de l'impl√©mentation de ce blocage centralis√©, vous pourriez constater que lors du partage d'un lien sur les r√©seaux sociaux, l'image d'illustration, le titre et la description ne s'affichent plus (Code d'erreur HTTP 403).

Cela arrive car certains r√©seaux sociaux utilisent des robots de "scraping" qui sont inclus par d√©faut dans les listes de blocage IA communautaires. Pour Facebook, il s'agit des agents :

* `facebookexternalhit` (le plus critique pour les aper√ßus)
* `FacebookBot`

### La Solution : Mise √† jour du script d'automatisation avec filtrage

Pour conserver la mise √† jour automatique via GitHub tout en prot√©geant la visibilit√© de vos liens, nous modifions le script pour qu'il "nettoie" la liste t√©l√©charg√©e (via la commande `sed`) avant de l'appliquer.

Voici la version optimis√©e et s√©curis√©e du script `/usr/local/bin/update_ai_blocklist.sh` :

```bash
#!/bin/bash

# Chemins et noms (√Ä ADAPTER !)
# Chemin de votre fichier de configuration NPM (doit pointer vers le volume mont√©)
CONFIG_FILE="/chemin/vers/data/nginx/custom/server_proxy.conf"
# URL du fichier brut NGINX sur GitHub
GITHUB_URL="https://raw.githubusercontent.com/ai-robots-txt/ai.robots.txt/main/nginx-block-ai-bots.conf"
# Nom de votre conteneur Docker NGINX Proxy Manager
NPM_CONTAINER_NAME="npm"

# --- D√©but de l'ex√©cution ---

echo "$(date) - D√©marrage de la mise √† jour de la liste de blocage AI..."

# 1. T√©l√©chargement de la nouvelle configuration
if curl -sL "$GITHUB_URL" -o "$CONFIG_FILE.new"; then
    echo "T√©l√©chargement r√©ussi."
    
    # 2. FILTRAGE S√âLECTIF : On retire les crawlers Facebook pour pr√©server les pr√©visualisations (OGP)
    # On supprime les occurrences pour √©viter le blocage 403 sur les r√©seaux sociaux
    sed -i 's/FacebookBot|//g' "$CONFIG_FILE.new"
    sed -i 's/facebookexternalhit|//g' "$CONFIG_FILE.new"
    echo "Nettoyage des crawlers Facebook effectu√©."
else
    echo "Erreur lors du t√©l√©chargement depuis GitHub."
    exit 1
fi

# 3. V√©rification et remplacement du fichier
if [ -s "$CONFIG_FILE.new" ]; then
    # D√©placement du nouveau fichier √† son emplacement final
    mv "$CONFIG_FILE.new" "$CONFIG_FILE"
    echo "Fichier de configuration mis √† jour."

    # 4. Validation de la syntaxe NGINX et recharge gracieuse
    if docker exec "$NPM_CONTAINER_NAME" nginx -t &> /dev/null; then
        echo "Syntaxe NGINX OK. Recharge gracieuse en cours..."
        docker exec "$NPM_CONTAINER_NAME" nginx -s reload
        echo "NGINX recharg√© avec succ√®s."
    else
        echo "ERREUR : Syntaxe NGINX invalide. Le proxy n'a PAS √©t√© recharg√©."
        echo "Veuillez v√©rifier le fichier : $CONFIG_FILE"
        exit 1
    fi
else
    echo "Le fichier t√©l√©charg√© est vide ou invalide. Aucune action effectu√©e."
    rm -f "$CONFIG_FILE.new"
    exit 1
fi

echo "$(date) - Mise √† jour termin√©e."

```